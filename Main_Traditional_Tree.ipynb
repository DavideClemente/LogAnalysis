{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS Anomaly Detection using LSTM\n",
    "\n",
    "## Importing data "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:14:01.139815Z",
     "start_time": "2025-04-30T14:13:53.648803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:04:00.052262Z",
     "start_time": "2025-04-30T15:03:57.846101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "BASE_PATH = os.getenv('BASE_PATH')\n",
    "\n",
    "traces = pd.read_csv(os.path.join(BASE_PATH, 'Raw_logs', 'HDFS_v1', 'preprocessed', 'Event_traces.csv'))\n",
    "labels = pd.read_csv(os.path.join(BASE_PATH, 'Raw_logs', 'HDFS_v1', 'preprocessed', 'anomaly_label.csv'))\n",
    "log_templates = pd.read_csv(os.path.join(BASE_PATH, 'Raw_logs', 'HDFS_v1', 'preprocessed', 'HDFS.log_templates.csv'))\n",
    "\n",
    "traces.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      BlockId    Label  Type  \\\n",
       "0                    blk_-1608999687919862906  Success   NaN   \n",
       "1  bl3544583377289625738k_7503483334202473044  Success   NaN   \n",
       "2                                       blk_-     Fail  21.0   \n",
       "3                    blk_-9073992586687739851  Success   NaN   \n",
       "4                     blk_7854771516489510256  Success   NaN   \n",
       "\n",
       "                                            Features  \\\n",
       "0  [E5,E22,E5,E5,E11,E11,E9,E9,E11,E9,E26,E26,E26...   \n",
       "1  [E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...   \n",
       "2  [E5,E22,E5,E5,E11,E9,E11,E9,E11,E9,E3,E26,E26,...   \n",
       "3  [E5,E22,E5,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...   \n",
       "4  [E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...   \n",
       "\n",
       "                                        TimeInterval  Latency  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3802  \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3802  \n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...     3797  \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    50448  \n",
       "4  [0.0, 0.0, 1.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    50583  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features</th>\n",
       "      <th>TimeInterval</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E5,E22,E5,E5,E11,E11,E9,E9,E11,E9,E26,E26,E26...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bl3544583377289625738k_7503483334202473044</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-</td>\n",
       "      <td>Fail</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[E5,E22,E5,E5,E11,E9,E11,E9,E11,E9,E3,E26,E26,...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E5,E22,E5,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>50448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_7854771516489510256</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E5,E5,E22,E5,E11,E9,E11,E9,E11,E9,E26,E26,E26...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>50583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:05:39.642333Z",
     "start_time": "2025-04-30T15:05:39.560058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'Objects' to lists\n",
    "import ast\n",
    "\n",
    "def parse_events(s):\n",
    "    # find all substrings matching “E” + digits\n",
    "    return re.findall(r'E\\d+', s)\n",
    "\n",
    "traces['Features'] = traces['Features'].apply(parse_events)\n",
    "traces.head()"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_events\u001B[39m(s):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# find all substrings matching “E” + digits\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m re\u001B[38;5;241m.\u001B[39mfindall(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+\u001B[39m\u001B[38;5;124m'\u001B[39m, s)\n\u001B[1;32m----> 8\u001B[0m traces[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeatures\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtraces\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mFeatures\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparse_events\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m traces\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py:4917\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[65], line 6\u001B[0m, in \u001B[0;36mparse_events\u001B[1;34m(s)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_events\u001B[39m(s):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# find all substrings matching “E” + digits\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfindall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mE\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43md+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\re.py:241\u001B[0m, in \u001B[0;36mfindall\u001B[1;34m(pattern, string, flags)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfindall\u001B[39m(pattern, string, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    234\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001B[39;00m\n\u001B[0;32m    235\u001B[0m \n\u001B[0;32m    236\u001B[0m \u001B[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    239\u001B[0m \n\u001B[0;32m    240\u001B[0m \u001B[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfindall\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstring\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: expected string or bytes-like object"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:05:40.387140Z",
     "start_time": "2025-04-30T15:05:40.338720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop type and latency columns\n",
    "traces = traces.drop(columns=['Type'], axis=1)\n",
    "traces = traces.drop(columns=['Latency'], axis=1)\n",
    "traces.info()"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Type'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Drop type and latency columns\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m traces \u001B[38;5;241m=\u001B[39m \u001B[43mtraces\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mType\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m traces \u001B[38;5;241m=\u001B[39m traces\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLatency\u001B[39m\u001B[38;5;124m'\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m traces\u001B[38;5;241m.\u001B[39minfo()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:5581\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5434\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5435\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5442\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5443\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5445\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[0;32m   5446\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5579\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[0;32m   5580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5583\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5587\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5588\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:4788\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4786\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4788\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:4830\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4828\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4829\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4830\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4831\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4833\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   7068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   7069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 7070\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   7071\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   7072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Type'] not found in axis\""
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:03:45.008989Z",
     "start_time": "2025-04-30T15:03:44.991178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing duplicate rows if any\n",
    "\n",
    "print('Shape before deleting duplicate values:', traces.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before deleting duplicate values: (287645, 4)\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:05:49.447451Z",
     "start_time": "2025-04-30T15:05:49.226129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing invalid blocks\n",
    "pattern = r'^blk_-[0-9]+$'\n",
    "traces = traces[traces['BlockId'].str.match(pattern, na=False)]\n",
    "traces.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     BlockId    Label  \\\n",
       "0   blk_-1608999687919862906  Success   \n",
       "3   blk_-9073992586687739851  Success   \n",
       "6   blk_-2519617320378473615  Success   \n",
       "10  blk_-2900490557492272760  Success   \n",
       "11    blk_-50273257731426871  Success   \n",
       "\n",
       "                                             Features  \\\n",
       "0   [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...   \n",
       "3   [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...   \n",
       "6   [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...   \n",
       "10  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...   \n",
       "11  [E5, E5, E22, E5, E9, E11, E9, E11, E11, E9, E...   \n",
       "\n",
       "                                         TimeInterval  \n",
       "0   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6   [0.0, 1.0, 9.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "10  [0.0, 0.0, 7.0, 44.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "11  [0.0, 0.0, 3.0, 39.0, 1.0, 0.0, 0.0, 0.0, 0.0,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Features</th>\n",
       "      <th>TimeInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Success</td>\n",
       "      <td>[E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Success</td>\n",
       "      <td>[E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blk_-2519617320378473615</td>\n",
       "      <td>Success</td>\n",
       "      <td>[E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...</td>\n",
       "      <td>[0.0, 1.0, 9.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blk_-2900490557492272760</td>\n",
       "      <td>Success</td>\n",
       "      <td>[E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
       "      <td>[0.0, 0.0, 7.0, 44.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blk_-50273257731426871</td>\n",
       "      <td>Success</td>\n",
       "      <td>[E5, E5, E22, E5, E9, E11, E9, E11, E11, E9, E...</td>\n",
       "      <td>[0.0, 0.0, 3.0, 39.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:05:51.486129Z",
     "start_time": "2025-04-30T15:05:51.407558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "goal = labels.Label\n",
    "counts = goal.value_counts()\n",
    "percent = goal.value_counts(normalize=True)\n",
    "percent100 = percent.mul(100).round(1).astype(str) + '%'\n",
    "pd.DataFrame({'Label': counts, 'percent': percent100})\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Label percent\n",
       "Label                  \n",
       "Normal   558223   97.1%\n",
       "Anomaly   16838    2.9%"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>558223</td>\n",
       "      <td>97.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anomaly</th>\n",
       "      <td>16838</td>\n",
       "      <td>2.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:05:57.758727Z",
     "start_time": "2025-04-30T15:05:56.762418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_events = (traces[['BlockId', 'Features']]\n",
    "             .explode('Features')\n",
    "             .rename(columns={'Features': 'Event'}))\n",
    "\n",
    "df_events"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         BlockId Event\n",
       "0       blk_-1608999687919862906    E5\n",
       "0       blk_-1608999687919862906   E22\n",
       "0       blk_-1608999687919862906    E5\n",
       "0       blk_-1608999687919862906    E5\n",
       "0       blk_-1608999687919862906   E11\n",
       "...                          ...   ...\n",
       "575060  blk_-9128742458709757181   E28\n",
       "575060  blk_-9128742458709757181   E26\n",
       "575060  blk_-9128742458709757181   E28\n",
       "575060  blk_-9128742458709757181   E26\n",
       "575060  blk_-9128742458709757181   E21\n",
       "\n",
       "[5587797 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>E5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>E22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>E5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>E5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>E11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575060</th>\n",
       "      <td>blk_-9128742458709757181</td>\n",
       "      <td>E28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575060</th>\n",
       "      <td>blk_-9128742458709757181</td>\n",
       "      <td>E26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575060</th>\n",
       "      <td>blk_-9128742458709757181</td>\n",
       "      <td>E28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575060</th>\n",
       "      <td>blk_-9128742458709757181</td>\n",
       "      <td>E26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575060</th>\n",
       "      <td>blk_-9128742458709757181</td>\n",
       "      <td>E21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5587797 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:06:40.102171Z",
     "start_time": "2025-04-30T15:06:20.027646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "event_counts = (\n",
    "    pd.crosstab(df_events['BlockId'], df_events['Event'])\n",
    ")\n",
    "event_counts"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event                     E1  E10  E11  E12  E13  E14  E15  E16  E17  E18  \\\n",
       "BlockId                                                                     \n",
       "blk_-1000002529962039464   0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-100000266894974466    0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-1000007292892887521   0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-1000014584150379967   0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-1000028658773048709   0    0    3    0    0    0    0    0    0    0   \n",
       "...                       ..  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "blk_-999650644387121533    0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-999754326029266890    0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-999918236066348879    0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-999925873043039166    0    0    3    0    0    0    0    0    0    0   \n",
       "blk_-999969827856922700    0    0    3    0    0    0    0    0    0    0   \n",
       "\n",
       "Event                     ...  E27  E28  E29  E3  E4  E5  E6  E7  E8  E9  \n",
       "BlockId                   ...                                             \n",
       "blk_-1000002529962039464  ...    0    0    0   0   0   3   0   0   0   3  \n",
       "blk_-100000266894974466   ...    0    0    0   6   3   3   0   0   0   3  \n",
       "blk_-1000007292892887521  ...    0    0    0   0   0   3   0   0   0   3  \n",
       "blk_-1000014584150379967  ...    0    0    0   6   3   3   0   0   0   3  \n",
       "blk_-1000028658773048709  ...    0    0    0   0   0   3   0   0   0   3  \n",
       "...                       ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  \n",
       "blk_-999650644387121533   ...    0    0    0   0   0   3   0   0   0   3  \n",
       "blk_-999754326029266890   ...    0    0    0   0   0   3   0   0   0   3  \n",
       "blk_-999918236066348879   ...    0    0    0   1   2   3   0   0   0   3  \n",
       "blk_-999925873043039166   ...    0    0    0   0   0   3   0   0   0   3  \n",
       "blk_-999969827856922700   ...    0    0    0   0   0   3   0   0   0   3  \n",
       "\n",
       "[287645 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Event</th>\n",
       "      <th>E1</th>\n",
       "      <th>E10</th>\n",
       "      <th>E11</th>\n",
       "      <th>E12</th>\n",
       "      <th>E13</th>\n",
       "      <th>E14</th>\n",
       "      <th>E15</th>\n",
       "      <th>E16</th>\n",
       "      <th>E17</th>\n",
       "      <th>E18</th>\n",
       "      <th>...</th>\n",
       "      <th>E27</th>\n",
       "      <th>E28</th>\n",
       "      <th>E29</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlockId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blk_-1000002529962039464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-100000266894974466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-1000007292892887521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-1000014584150379967</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-1000028658773048709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-999650644387121533</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-999754326029266890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-999918236066348879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-999925873043039166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_-999969827856922700</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287645 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:38:16.595301Z",
     "start_time": "2025-04-30T14:38:16.557678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many missing values are in the dataset?\n",
    "traces.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockId         0\n",
       "Label           0\n",
       "Features        0\n",
       "TimeInterval    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:38:13.775027Z",
     "start_time": "2025-04-30T14:38:13.722137Z"
    }
   },
   "cell_type": "code",
   "source": "traces.isna().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockId         0\n",
       "Label           0\n",
       "Features        0\n",
       "TimeInterval    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:44:28.602439Z",
     "start_time": "2025-04-30T14:44:28.461388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = traces.drop('Label', axis=1)\n",
    "y = traces['Label'].map({'Success': 0, 'Fail': 1})\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:44:15.346650Z",
     "start_time": "2025-04-30T14:44:15.291339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply smote to balance the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='auto',\n",
    "    k_neighbors=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "x_train_res, y_train_res = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts(normalize=True))\n",
    "print(\" After SMOTE:\", y_train_res.value_counts(normalize=True))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davide\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'blk_-620208026821375986'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_29904\\2158934347.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[1;31m# Apply smote to balance the dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mimblearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mover_sampling\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSMOTE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    204\u001B[0m         \u001B[0my_resampled\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlike\u001B[0m \u001B[0mof\u001B[0m \u001B[0mshape\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mn_samples_new\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    205\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mof\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mX_resampled\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m         \"\"\"\n\u001B[0;32m    207\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_resample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    102\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mof\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mX_resampled\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    103\u001B[0m         \"\"\"\n\u001B[0;32m    104\u001B[0m         \u001B[0mcheck_classification_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m         \u001B[0marrays_transformer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mArraysTransformer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 106\u001B[1;33m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    107\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    108\u001B[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001B[0;32m    109\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msampling_strategy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampling_type\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, accept_sparse)\u001B[0m\n\u001B[0;32m    157\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_check_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0maccept_sparse\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m             \u001B[0maccept_sparse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"csr\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_target_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindicate_one_vs_all\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 161\u001B[1;33m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    162\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    476\u001B[0m             \u001B[1;34m\"in 1.7. Use `sklearn.utils.validation.validate_data` instead. This \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    477\u001B[0m             \u001B[1;34m\"function becomes public and is part of the scikit-learn developer API.\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    478\u001B[0m             \u001B[0mFutureWarning\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    479\u001B[0m         )\n\u001B[1;32m--> 480\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mvalidate_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[0m\n\u001B[0;32m   2957\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;34m\"estimator\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2958\u001B[0m                 \u001B[0mcheck_y_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2959\u001B[0m             \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2960\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2961\u001B[1;33m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2962\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2963\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2964\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ensure_2d\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1366\u001B[0m         )\n\u001B[0;32m   1367\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1368\u001B[0m     \u001B[0mensure_all_finite\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_deprecate_force_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_all_finite\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1370\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m   1371\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1372\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1373\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1053\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1054\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1056\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1057\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m   1058\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1059\u001B[0m                 ) from complex_warning\n\u001B[0;32m   1060\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[0;32m    835\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    836\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    837\u001B[0m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 839\u001B[1;33m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    840\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    841\u001B[0m         \u001B[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m         \u001B[1;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m   2149\u001B[0m     def __array__(\n\u001B[0;32m   2150\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool_t\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2151\u001B[0m     ) -> np.ndarray:\n\u001B[0;32m   2152\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2153\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2154\u001B[0m         if (\n\u001B[0;32m   2155\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2156\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'blk_-620208026821375986'"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(event_sequences, label, window_size_local=10, step_size_local=1):\n",
    "    x1, y1 = [], []\n",
    "    for i in range(0, len(event_sequences) - window_size_local, step_size_local):\n",
    "        x1.append(event_sequences[i: i + window_size_local])\n",
    "        y1.append(label)\n",
    "    return np.array(x1), np.array(y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "VOCAB_SIZE = len(log_templates['EventId'].unique()) + 1\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,  # Set your desired vocabulary size\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LEN  # Set your desired sequence length\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(log_templates['EventId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"variables\", \"x_train.npy\")) and os.path.exists(\n",
    "        os.path.join(\"variables\", \"y_train.npy\")):\n",
    "    x_train = np.load(os.path.join(\"variables\", \"x_train.npy\"))\n",
    "    y_train = np.load(os.path.join(\"variables\", \"y_train.npy\"))\n",
    "else:\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "\n",
    "    window_size = 10\n",
    "    step_size = 1\n",
    "\n",
    "    for i in tqdm(range(len(data)), desc=\"Processing events\", unit=\"log\"):\n",
    "        raw_text = data['Features'][i][1:-1].replace(\",\", \" \")\n",
    "        x_vectorized = vectorize_layer(raw_text)\n",
    "        label = data['Label'][i]\n",
    "        x_windows, y_windows = create_sliding_windows(x_vectorized, label, window_size, step_size)\n",
    "\n",
    "        x_all.append(x_windows)\n",
    "        y_all.append(y_windows)\n",
    "\n",
    "    x_train = np.concatenate(x_all, axis=0)\n",
    "    y_train = np.concatenate(y_all, axis=0)\n",
    "\n",
    "print(f\"X_Train {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"variables\", exist_ok=True)\n",
    "np.save(os.path.join(\"variables\", \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(\"variables\", \"y_train.npy\"), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x_train, y_train, test_size=0.2,\n",
    "                                                                            random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vectorize_layer.vocabulary_size(), embedding_vector_length))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelDropout = Sequential()\n",
    "modelDropout.add(Embedding(vectorize_layer.vocabulary_size(), embedding_vector_length))\n",
    "modelDropout.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "modelDropout.add(Dense(1, activation='sigmoid'))\n",
    "modelDropout.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "print(model.summary())\n",
    "print(modelDropout.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_final),\n",
    "    y=y_train_final.ravel()\n",
    ")\n",
    "\n",
    "# Converter para dicionário:\n",
    "weights = dict(zip(np.unique(y_train_final), class_weights))\n",
    "\n",
    "print(weights)\n",
    "\n",
    "checkpoint = ModelCheckpoint('models/lstm_model_best_dropout.keras', monitor='val_accuracy', save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "model_path = os.path.join('models', 'lstm_model_best_dropout.keras')\n",
    "if os.path.exists(model_path):\n",
    "    print('Loading existing model.')\n",
    "    modelDropout = load_model(model_path)\n",
    "else:\n",
    "    print('Model not found, training a new one.')\n",
    "    # Train the LSTM model\n",
    "    modelDropout.fit(x_train_final, y_train_final,\n",
    "                     validation_data=(x_test_final, y_test_final),\n",
    "                     epochs=3, batch_size=512,\n",
    "                     class_weight=weights,\n",
    "                     callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \" \".join(event_sequence)\n",
    "x_vectorized = vectorize_layer(text_input)\n",
    "x_windows, _ = create_sliding_windows(x_vectorized, None)\n",
    "predictions = model.predict(x_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(predictions)\n",
    "plt.title(\"Failure Probability over Time\")\n",
    "plt.xlabel(\"Window Index\")\n",
    "plt.ylabel(\"Failure Probability\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EventId                           EventTemplate\n",
      "0      E1  [*]Adding an already existing block[*]\n",
      "1      E2        [*]Verification succeeded for[*]\n",
      "2      E3                 [*]Served block[*]to[*]\n",
      "3      E4  [*]Got exception while serving[*]to[*]\n",
      "4      E5    [*]Receiving block[*]src:[*]dest:[*]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing log lines: 855118line [03:21, 4236.09line/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(log_file_path, \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[32m     30\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m tqdm(file, desc=\u001B[33m\"\u001B[39m\u001B[33mProcessing log lines\u001B[39m\u001B[33m\"\u001B[39m, unit=\u001B[33m\"\u001B[39m\u001B[33mline\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m         event_id = \u001B[43mmap_log_to_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m event_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     33\u001B[39m             event_sequence.append(event_id)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mmap_log_to_event\u001B[39m\u001B[34m(log_line)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmap_log_to_event\u001B[39m(log_line):\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlog_templates\u001B[49m\u001B[43m.\u001B[49m\u001B[43miterrows\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mRegex\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_line\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mreturn\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mEventId\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv-tfmetal/lib/python3.12/site-packages/pandas/core/frame.py:1554\u001B[39m, in \u001B[36mDataFrame.iterrows\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1552\u001B[39m using_cow = using_copy_on_write()\n\u001B[32m   1553\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m.index, \u001B[38;5;28mself\u001B[39m.values):\n\u001B[32m-> \u001B[39m\u001B[32m1554\u001B[39m     s = \u001B[43mklass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m.__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m   1555\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m using_cow \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._mgr.is_single_block:\n\u001B[32m   1556\u001B[39m         s._mgr.add_references(\u001B[38;5;28mself\u001B[39m._mgr)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv-tfmetal/lib/python3.12/site-packages/pandas/core/series.py:584\u001B[39m, in \u001B[36mSeries.__init__\u001B[39m\u001B[34m(self, data, index, dtype, name, copy, fastpath)\u001B[39m\n\u001B[32m    582\u001B[39m         data = data.copy()\n\u001B[32m    583\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m584\u001B[39m     data = \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    586\u001B[39m     manager = _get_option(\u001B[33m\"\u001B[39m\u001B[33mmode.data_manager\u001B[39m\u001B[33m\"\u001B[39m, silent=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    587\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m manager == \u001B[33m\"\u001B[39m\u001B[33mblock\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv-tfmetal/lib/python3.12/site-packages/pandas/core/construction.py:606\u001B[39m, in \u001B[36msanitize_array\u001B[39m\u001B[34m(data, index, dtype, copy, allow_2d)\u001B[39m\n\u001B[32m    604\u001B[39m subarr = data\n\u001B[32m    605\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m data.dtype == \u001B[38;5;28mobject\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m606\u001B[39m     subarr = \u001B[43mmaybe_infer_to_datetimelike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    607\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    608\u001B[39m         object_index\n\u001B[32m    609\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m using_pyarrow_string_dtype()\n\u001B[32m    610\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m is_string_dtype(subarr)\n\u001B[32m    611\u001B[39m     ):\n\u001B[32m    612\u001B[39m         \u001B[38;5;66;03m# Avoid inference when string option is set\u001B[39;00m\n\u001B[32m    613\u001B[39m         subarr = data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv-tfmetal/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:1189\u001B[39m, in \u001B[36mmaybe_infer_to_datetimelike\u001B[39m\u001B[34m(value)\u001B[39m\n\u001B[32m   1184\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[32m   1186\u001B[39m \u001B[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001B[39;00m\n\u001B[32m   1187\u001B[39m \u001B[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001B[39;00m\n\u001B[32m   1188\u001B[39m \u001B[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1189\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmaybe_convert_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[return-value]\u001B[39;49;00m\n\u001B[32m   1190\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001B[39;49;00m\n\u001B[32m   1192\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#  numpy would have done it for us.\u001B[39;49;00m\n\u001B[32m   1193\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconvert_numeric\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconvert_non_numeric\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype_if_all_nat\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mM8[ns]\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2543\u001B[39m, in \u001B[36mpandas._libs.lib.maybe_convert_objects\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/venv-tfmetal/lib/python3.12/site-packages/numpy/_core/numeric.py:366\u001B[39m, in \u001B[36mfull\u001B[39m\u001B[34m(shape, fill_value, dtype, order, device, like)\u001B[39m\n\u001B[32m    364\u001B[39m     dtype = fill_value.dtype\n\u001B[32m    365\u001B[39m a = empty(shape, dtype, order, device=device)\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m \u001B[43mmultiarray\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcopyto\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43munsafe\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "BASE_PATH = \"~\"\n",
    "\n",
    "log_templates = pd.read_csv(os.path.join(BASE_PATH, 'Raw_logs', 'HDFS_v1', 'preprocessed', 'HDFS.log_templates.csv'))\n",
    "print(log_templates.head())\n",
    "log_templates['Regex'] = log_templates['EventTemplate'].apply(\n",
    "    lambda t: re.compile(re.escape(t).replace(r'\\[\\*\\]', '.*')))\n",
    "\n",
    "\n",
    "def map_log_to_event(log_line):\n",
    "    for _, row in log_templates.iterrows():\n",
    "        if row['Regex'].match(log_line):\n",
    "            return row['EventId']\n",
    "    return None\n",
    "\n",
    "\n",
    "log_file_path = os.path.expanduser(os.path.join(BASE_PATH, 'Raw_logs', 'HDFS_v1', 'HDFS.log'))\n",
    "\n",
    "if not os.path.exists(log_file_path):\n",
    "    raise FileNotFoundError(f\"No such file or directory: '{log_file_path}'\")\n",
    "\n",
    "event_sequence = []\n",
    "with open(log_file_path, 'r') as file:\n",
    "    for line in tqdm(file, desc=\"Processing log lines\", unit=\"line\"):\n",
    "        event_id = map_log_to_event(line.strip())\n",
    "        if event_id is not None:\n",
    "            event_sequence.append(event_id)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
